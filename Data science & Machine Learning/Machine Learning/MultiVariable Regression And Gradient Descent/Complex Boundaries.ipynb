{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "X = boston.data\n",
    "Y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(X)\n",
    "print(boston.feature_names)\n",
    "df.columns = boston.feature_names\n",
    "df[\"age_age\"] = df.AGE ** 2\n",
    "df.describe()\n",
    "X2 = df.values\n",
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, random_state = 0)\n",
    "X2_train, X2_test, Y2_train, Y2_test = model_selection.train_test_split(X2, Y, random_state = 0)\n",
    "#random_state=0 same rows goes for training in x as well as x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "alg1 = LinearRegression()\n",
    "alg2 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg1.fit(X_train, Y_train)\n",
    "alg2.fit(X2_train, Y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.7697699488741149\n",
      "Test Score:  0.6354638433202103\n",
      "Train2 Score:  0.770724544991109\n",
      "Test2 Score:  0.6433109272342938\n"
     ]
    }
   ],
   "source": [
    "Y_pred = alg1.predict(X_test)\n",
    "train_score = alg1.score(X_train, Y_train)\n",
    "test_score = alg1.score(X_test, Y_test)\n",
    "print(\"Train Score: \", train_score)\n",
    "print(\"Test Score: \", test_score)\n",
    "\n",
    "train2_score = alg2.score(X2_train, Y2_train)\n",
    "test2_score = alg2.score(X2_test, Y2_test)\n",
    "print(\"Train2 Score: \", train2_score)\n",
    "print(\"Test2 Score: \", test2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by adding 1 feature score has improved.\n",
    "(See testing score change always)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(X)\n",
    "print(boston.feature_names)\n",
    "df.columns = boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 207. MiB for an array with shape (53491, 506) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\mridu\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'new_ZN_new_CRIM_bina_bina_B_CRIM_bina_RAD_INDUS'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\mridu\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, item, value)\u001b[0m\n\u001b[0;32m   1070\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1071\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mridu\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'new_ZN_new_CRIM_bina_bina_B_CRIM_bina_RAD_INDUS'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-a6ceda783af2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_new\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mbina\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'new_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbina\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\mridu\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2937\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2938\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mridu\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2999\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3000\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3001\u001b[1;33m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3003\u001b[0m         \u001b[1;31m# check if we are modifying a copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mridu\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3623\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3624\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3625\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mridu\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, item, value)\u001b[0m\n\u001b[0;32m   1072\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m             \u001b[1;31m# This item wasn't present, just insert at end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1074\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1075\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mridu\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m     def reindex_axis(\n",
      "\u001b[1;32mc:\\users\\mridu\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 945\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mridu\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   1884\u001b[0m     \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1886\u001b[1;33m         merged_blocks = _merge_blocks(\n\u001b[0m\u001b[0;32m   1887\u001b[0m             \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_can_consolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1888\u001b[0m         )\n",
      "\u001b[1;32mc:\\users\\mridu\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[0;32m   3100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3101\u001b[0m         \u001b[0margsort\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3102\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3103\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 207. MiB for an array with shape (53491, 506) and data type float64"
     ]
    }
   ],
   "source": [
    "\n",
    "df_new = df.columns.values\n",
    "\n",
    "for i in df_new:\n",
    "    for j in df_new:\n",
    "        bina = df[i] * df[j]\n",
    "        df['new_' + str(i) + '_' + str(j)] = bina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', ..., 'bina_bina_LSTAT_B_bina_LSTAT_TAX',\n",
       "       'bina_bina_LSTAT_B_bina_LSTAT_PTRATIO',\n",
       "       'bina_bina_LSTAT_B_bina_LSTAT_B'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3=list_ib.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, random_state = 0)\n",
    "X3_train, X3_test, Y3_train, Y3_test = model_selection.train_test_split(X3, Y, random_state = 0)\n",
    "#random_state=0 same rows goes for training in x as well as x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is an optimization algorithm used to find the values of parameters (coefficients) of a function (f) that minimizes a cost function (cost).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If learning rate is high:\n",
    "there is a risk of overshooting the lowest point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient(points, learning_rate, m , c):\n",
    "    m_slope = 0\n",
    "    c_slope = 0\n",
    "    M = len(points)\n",
    "    for i in range(M):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        m_slope += (-2/M)* (y - m * x - c)*x\n",
    "        c_slope += (-2/M)* (y - m * x - c)\n",
    "    new_m = m - learning_rate*m_slope\n",
    "    new_c = c - learning_rate*c_slope\n",
    "    return new_m, new_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(points, learning_rate, num_iterations):\n",
    "    m = 0\n",
    "    c = 0\n",
    "    for i in range(num_iterations):\n",
    "        m, c = step_gradient(points, learning_rate, m , c)\n",
    "        print(i, \" Cost: \", cost(points, m, c))\n",
    "    return m, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(points, m, c):\n",
    "    total_cost = 0\n",
    "    M = len(points)\n",
    "    for i in range(M):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        total_cost += (1/M)*((y - m*x - c)**2)\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    data = np.loadtxt(\"data.csv\", delimiter=\",\")\n",
    "    learning_rate = 0.0001\n",
    "    num_iterations = 100\n",
    "    m, c = gd(data, learning_rate, num_iterations)\n",
    "    print(m, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Cost:  1484.5865574086486\n",
      "1  Cost:  457.8542575737672\n",
      "2  Cost:  199.5099857255389\n",
      "3  Cost:  134.50591058200533\n",
      "4  Cost:  118.1496934223995\n",
      "5  Cost:  114.0341490603815\n",
      "6  Cost:  112.99857731713657\n",
      "7  Cost:  112.73798187568467\n",
      "8  Cost:  112.6723843590911\n",
      "9  Cost:  112.65585181499745\n",
      "10  Cost:  112.65166489759581\n",
      "11  Cost:  112.6505843615011\n",
      "12  Cost:  112.65028544701502\n",
      "13  Cost:  112.65018320293967\n",
      "14  Cost:  112.650130445072\n",
      "15  Cost:  112.65009013922885\n",
      "16  Cost:  112.6500529669463\n",
      "17  Cost:  112.65001658353178\n",
      "18  Cost:  112.64998039901865\n",
      "19  Cost:  112.64994426496071\n",
      "20  Cost:  112.64990814400622\n",
      "21  Cost:  112.64987202675677\n",
      "22  Cost:  112.64983591084761\n",
      "23  Cost:  112.64979979568368\n",
      "24  Cost:  112.64976368111523\n",
      "25  Cost:  112.64972756710469\n",
      "26  Cost:  112.64969145364236\n",
      "27  Cost:  112.64965534072611\n",
      "28  Cost:  112.64961922835512\n",
      "29  Cost:  112.64958311652944\n",
      "30  Cost:  112.64954700524868\n",
      "31  Cost:  112.64951089451318\n",
      "32  Cost:  112.64947478432279\n",
      "33  Cost:  112.64943867467744\n",
      "34  Cost:  112.64940256557728\n",
      "35  Cost:  112.64936645702221\n",
      "36  Cost:  112.64933034901203\n",
      "37  Cost:  112.64929424154704\n",
      "38  Cost:  112.64925813462712\n",
      "39  Cost:  112.6492220282522\n",
      "40  Cost:  112.64918592242235\n",
      "41  Cost:  112.64914981713754\n",
      "42  Cost:  112.64911371239779\n",
      "43  Cost:  112.64907760820296\n",
      "44  Cost:  112.64904150455324\n",
      "45  Cost:  112.64900540144845\n",
      "46  Cost:  112.64896929888867\n",
      "47  Cost:  112.64893319687388\n",
      "48  Cost:  112.6488970954041\n",
      "49  Cost:  112.64886099447922\n",
      "50  Cost:  112.64882489409929\n",
      "51  Cost:  112.64878879426433\n",
      "52  Cost:  112.64875269497436\n",
      "53  Cost:  112.64871659622933\n",
      "54  Cost:  112.64868049802914\n",
      "55  Cost:  112.648644400374\n",
      "56  Cost:  112.64860830326366\n",
      "57  Cost:  112.64857220669828\n",
      "58  Cost:  112.64853611067772\n",
      "59  Cost:  112.64850001520212\n",
      "60  Cost:  112.64846392027131\n",
      "61  Cost:  112.64842782588545\n",
      "62  Cost:  112.64839173204442\n",
      "63  Cost:  112.6483556387483\n",
      "64  Cost:  112.64831954599697\n",
      "65  Cost:  112.64828345379043\n",
      "66  Cost:  112.64824736212877\n",
      "67  Cost:  112.64821127101193\n",
      "68  Cost:  112.64817518043986\n",
      "69  Cost:  112.64813909041264\n",
      "70  Cost:  112.64810300093015\n",
      "71  Cost:  112.64806691199259\n",
      "72  Cost:  112.64803082359971\n",
      "73  Cost:  112.64799473575155\n",
      "74  Cost:  112.64795864844827\n",
      "75  Cost:  112.64792256168963\n",
      "76  Cost:  112.64788647547579\n",
      "77  Cost:  112.64785038980668\n",
      "78  Cost:  112.64781430468226\n",
      "79  Cost:  112.64777822010265\n",
      "80  Cost:  112.6477421360677\n",
      "81  Cost:  112.64770605257743\n",
      "82  Cost:  112.64766996963193\n",
      "83  Cost:  112.64763388723107\n",
      "84  Cost:  112.64759780537483\n",
      "85  Cost:  112.64756172406335\n",
      "86  Cost:  112.6475256432965\n",
      "87  Cost:  112.64748956307432\n",
      "88  Cost:  112.64745348339677\n",
      "89  Cost:  112.64741740426388\n",
      "90  Cost:  112.6473813256756\n",
      "91  Cost:  112.64734524763193\n",
      "92  Cost:  112.64730917013293\n",
      "93  Cost:  112.6472730931785\n",
      "94  Cost:  112.64723701676861\n",
      "95  Cost:  112.64720094090339\n",
      "96  Cost:  112.64716486558265\n",
      "97  Cost:  112.64712879080662\n",
      "98  Cost:  112.64709271657513\n",
      "99  Cost:  112.64705664288809\n",
      "1.4788027175308358 0.035074970592341756\n"
     ]
    }
   ],
   "source": [
    "run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the cost gradient based on the complete training set; hence, we sometimes also call it batch gd. In case of very large datasets, using this gradient descent can be quite costly since we are only taking a single step for one pass over the training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Uses n data points instead of 1 sample at each iteration. : Mini-batch gradient descent \n",
    "2. Computes the gradient using a single sample. : Stochastic gradient descent\n",
    "3. Computes the gradient using the whole dataset. : Batch gradient descent \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.330945601757023\n",
      "9.637146448555411\n",
      "5.953660858003798\n",
      "4.5057366314806435\n",
      "3.8873536780750935\n",
      "3.603202441925844\n",
      "3.4420604912244936\n",
      "3.3427757441875063\n",
      "3.2520696230052097\n",
      "3.176973447107825\n",
      "3.102616683744968\n",
      "3.0518023829908185\n",
      "2.9894974679332758\n",
      "2.936367432101647\n",
      "2.8670950472861474\n",
      "2.8163083916965936\n",
      "2.747282606925516\n",
      "2.6878761485855964\n",
      "2.6353355963326353\n",
      "2.5822349821824364\n",
      "2.5315025820638506\n",
      "2.4778034324195906\n",
      "2.430948685423539\n",
      "2.3900591885855924\n",
      "2.3385723267674132\n",
      "2.2927213226567447\n",
      "2.2565270598899434\n",
      "2.2324626095342106\n",
      "2.1931359511152335\n",
      "2.1598311119057563\n",
      "2.1246469540006077\n",
      "2.0937683723800555\n",
      "2.0612041909176106\n",
      "2.036240921787178\n",
      "2.0050053794156355\n",
      "1.9816450489808528\n",
      "1.9547285059769013\n",
      "1.9328082947516088\n",
      "1.9164832061350097\n",
      "1.8991268550678149\n",
      "1.8807506725381682\n",
      "1.8574898357792766\n",
      "1.828241219020384\n",
      "1.812362690245684\n",
      "1.7999506708780935\n",
      "1.7834477443168306\n",
      "1.7770262812338313\n",
      "1.7673303852654483\n",
      "1.7516325176765182\n",
      "1.7380321350678205\n",
      "1.7237325960164402\n",
      "1.7191332783879862\n",
      "1.725440434198259\n",
      "1.718684001075729\n",
      "1.7126323803642667\n",
      "1.7024983881113027\n",
      "1.6935848394946984\n",
      "1.6850752602061654\n",
      "1.677373619573758\n",
      "1.671343221036209\n",
      "1.6670403617081426\n",
      "1.668650539376133\n",
      "1.6643618716686235\n",
      "1.6514013653049895\n",
      "1.6450672440006389\n",
      "1.6367907953445169\n",
      "1.6314833657397747\n",
      "1.6281097278346335\n",
      "1.6252091619453057\n",
      "1.622205469810923\n",
      "1.6220580574393815\n",
      "1.616321178427524\n",
      "1.613437691668629\n",
      "1.607795403249659\n",
      "1.6027633366488663\n",
      "1.6000577347911644\n",
      "1.5979850820243606\n",
      "1.5976059449097393\n",
      "1.596410333486813\n",
      "1.5923036581113197\n",
      "1.5862773826567755\n",
      "1.5859578917081587\n",
      "1.586351748822781\n",
      "1.5835828349492573\n",
      "1.5820343647121078\n",
      "1.5809929900480693\n",
      "1.5806649634472825\n",
      "1.5761174155026143\n",
      "1.5737099117476712\n",
      "1.5743620527358184\n",
      "1.5756244155421384\n",
      "1.5767259804038\n",
      "1.5771369244749474\n",
      "1.5774447423010327\n",
      "1.5770392120638805\n",
      "1.5757140812733623\n",
      "1.5743889504828499\n",
      "1.5730638196923385\n",
      "1.5709222145935233\n",
      "1.5663311865698077\n",
      "1.5633731071626946\n",
      "1.561761324909727\n",
      "1.5591959185460946\n",
      "1.5592436283879922\n",
      "1.5587151399690207\n",
      "1.557267050996691\n",
      "1.5557849384670472\n",
      "1.5504267068860151\n",
      "1.5487383418662535\n",
      "1.5478664511547926\n",
      "1.546891434198272\n",
      "1.5474916941587455\n",
      "1.5463218557002474\n",
      "1.5442324166883852\n",
      "1.5443861481113117\n",
      "1.5436202789808802\n",
      "1.5434646316686247\n",
      "1.5449419329729717\n",
      "1.5463161080322623\n",
      "1.5468738087832477\n",
      "1.5457985609176328\n",
      "1.5463902852259344\n",
      "1.5476953575974788\n",
      "1.546516983486805\n",
      "1.5454417356211874\n",
      "1.5457931838820569\n",
      "1.5460415058978643\n",
      "1.544782732814855\n",
      "1.5427074854235552\n",
      "1.5421620604037916\n",
      "1.5424331096923303\n",
      "1.5435206332891678\n",
      "1.545218378704187\n",
      "1.5468129978741505\n",
      "1.5468777946725705\n",
      "1.54541276909945\n",
      "1.5454775658978703\n",
      "1.5455423626962914\n",
      "1.5448938114314699\n",
      "1.546385304356368\n",
      "1.5470603229729682\n",
      "1.545595297399845\n",
      "1.5448436198899653\n",
      "1.5433785943168459\n",
      "1.542730043052023\n",
      "1.5427948398504443\n",
      "1.5435729847121002\n",
      "1.5436377815105211\n",
      "1.54523240068049\n",
      "1.5468270198504506\n",
      "1.5460753423405706\n",
      "1.5477730877555924\n",
      "1.5471245364907702\n",
      "1.549535629969033\n",
      "1.5496004267674561\n",
      "1.5504816978741738\n",
      "1.5521794432891969\n",
      "1.5515308920243756\n",
      "1.551698815067854\n",
      "1.551866738111333\n",
      "1.552034661154811\n",
      "1.5523057104433486\n",
      "1.5525767597318851\n",
      "1.552847809020424\n",
      "1.5530157320639062\n",
      "1.5523671807990826\n",
      "1.5517186295342573\n",
      "1.5540265967674578\n",
      "1.552561571194341\n",
      "1.5519130199295166\n",
      "1.5527138920639048\n",
      "1.5521911943168718\n",
      "1.5523818446330775\n",
      "1.551778747913705\n",
      "1.5519921255026405\n",
      "1.5522055030915756\n",
      "1.5500725840006662\n",
      "1.5479396649097596\n",
      "1.5473592954631226\n",
      "1.5483087483880213\n",
      "1.549258201312922\n",
      "1.5503107804828853\n",
      "1.5505468853445443\n",
      "1.550782990206209\n",
      "1.5527087945145146\n",
      "1.552391428388026\n",
      "1.5519596397318995\n",
      "1.55163097732083\n",
      "1.5521187892180628\n",
      "1.553423075423597\n",
      "1.5547273616291288\n",
      "1.5535822249097608\n",
      "1.5524370881903962\n",
      "1.551291951471025\n",
      "1.5485138661350564\n",
      "1.5472883304433545\n",
      "1.5476957433682552\n",
      "1.547286681984856\n",
      "1.5460611462931602\n",
      "1.5449387368465164\n",
      "1.5431029793366349\n",
      "1.5427970441982957\n",
      "1.542491109059955\n",
      "1.5421851739216148\n",
      "1.5418792387832703\n",
      "1.5423897779532338\n",
      "1.5412673685065943\n",
      "1.5401449590599525\n",
      "1.5399421501666686\n",
      "1.538922866965088\n",
      "1.538616931826749\n",
      "1.5391274709967087\n",
      "1.540351358229905\n",
      "1.5399082732891975\n",
      "1.5387518402852418\n",
      "1.5374922810362317\n",
      "1.5362327217872167\n",
      "1.5356865106014486\n",
      "1.5351402994156773\n",
      "1.5337776139216068\n",
      "1.5339447507990756\n",
      "1.5333985396133052\n",
      "1.5344048780718036\n",
      "1.5345947422219999\n",
      "1.5347846063722024\n",
      "1.53325991866469\n",
      "1.531735230957182\n",
      "1.5293571578741758\n",
      "1.5269790847911735\n",
      "1.5254174860164715\n",
      "1.5276288800480926\n",
      "1.5274939773998701\n",
      "1.5281755490599558\n",
      "1.5295704687832754\n",
      "1.5294355661350525\n",
      "1.530014011550073\n",
      "1.5313058050283366\n",
      "1.5327007247516604\n",
      "1.5326689483484968\n",
      "1.5326031483880214\n",
      "1.5317208741192503\n",
      "1.5308385998504712\n",
      "1.5299563255816961\n",
      "1.5290740513129208\n",
      "1.5298587492180629\n",
      "1.5299300990599622\n",
      "1.5300014489018572\n",
      "1.5300727987437586\n",
      "1.5308234730915804\n",
      "1.5299411988228055\n",
      "1.5298753988623301\n",
      "1.5289931245935575\n",
      "1.528721072142964\n",
      "1.5285521459374332\n",
      "1.5299130421034395\n",
      "1.530560590206207\n",
      "1.530494790245729\n",
      "1.5312454645935605\n",
      "1.5297529685066047\n",
      "1.5282604724196431\n",
      "1.5266648500876288\n",
      "1.5265990501271551\n",
      "1.5279599462931637\n",
      "1.5285043681508739\n",
      "1.529762138071826\n",
      "1.5303065599295367\n",
      "1.530850981787241\n",
      "1.5313613800876356\n",
      "1.5310553040797295\n",
      "1.5307492280718245\n",
      "1.5297298040006797\n",
      "1.5301370760560213\n",
      "1.529831000048114\n",
      "1.5303413983485075\n",
      "1.5300353223406042\n",
      "1.529729246332701\n",
      "1.5294231703247976\n",
      "1.529830442380133\n",
      "1.5279945440006872\n",
      "1.5290811405619515\n",
      "1.5294543890599808\n",
      "1.5298276375580009\n",
      "1.5317307084275695\n",
      "1.5343471273603795\n",
      "1.5330874272418\n",
      "1.5326442014315265\n",
      "1.5343410198109695\n",
      "1.5368543124987135\n",
      "1.5371244347516788\n",
      "1.5366812089414037\n",
      "1.5362379831311286\n",
      "1.5357947573208504\n",
      "1.535351531510577\n",
      "1.5349083057002997\n",
      "1.5337517318267824\n",
      "1.5325951579532646\n",
      "1.532151932142987\n",
      "1.5317087063327144\n",
      "1.531402630324807\n",
      "1.5310965543169022\n",
      "1.5315038263722385\n",
      "1.529667927992796\n",
      "1.5306854218663084\n",
      "1.5310926939216452\n",
      "1.5314999659769852\n",
      "1.5311938899690827\n",
      "1.5308878139611757\n",
      "1.5282354412734298\n",
      "1.526399542893981\n",
      "1.5284397635659188\n",
      "1.530583110482917\n",
      "1.5303801607200718\n",
      "1.5309936852655268\n",
      "1.5330339059374654\n",
      "1.5328309561746198\n",
      "1.5324908566093989\n",
      "1.5336805794157264\n",
      "1.5340538279137448\n",
      "1.534323950166715\n",
      "1.5337775981113762\n",
      "1.5347610684275892\n",
      "1.5349280644354966\n",
      "1.5351981866884619\n",
      "1.5347549608781845\n",
      "1.5351282093762078\n",
      "1.5347881098109943\n",
      "1.5351613583090176\n",
      "1.534004784435499\n",
      "1.532848210561981\n",
      "1.5309782886252237\n",
      "1.531454663368303\n",
      "1.531931038111385\n",
      "1.5317280883485385\n",
      "1.53223848664894\n",
      "1.5327716122220592\n",
      "1.5333047377951847\n",
      "1.5330213890600033\n",
      "1.5327380403248274\n",
      "1.531741343526409\n",
      "1.5323775953445924\n",
      "1.5313808985461732\n",
      "1.5312006760560568\n",
      "1.531020453565934\n",
      "1.5316567053841184\n",
      "1.5314764828939986\n",
      "1.5321127347121801\n",
      "1.5319325122220626\n",
      "1.5317750170046698\n",
      "1.5316175217872787\n",
      "1.5306435522615844\n",
      "1.5304860570441967\n",
      "1.529512087518503\n",
      "1.528538117992817\n",
      "1.5275641484671227\n",
      "1.5265901789414318\n",
      "1.5280656323406419\n",
      "1.5278277381509213\n",
      "1.5307753422220662\n",
      "1.5329064719849108\n",
      "1.534324253684518\n",
      "1.536455383447366\n",
      "1.5378731651469715\n",
      "1.538577598783336\n",
      "1.5392820324196994\n",
      "1.5391699917477617\n",
      "1.540850776767526\n",
      "1.5417150874789918\n",
      "1.5416257740797767\n",
      "1.543169409297167\n",
      "1.5438161712339302\n",
      "1.5451762812339271\n",
      "1.5459261694157507\n",
      "1.5458595832892668\n",
      "1.5465063452260273\n",
      "1.5464397590995445\n",
      "1.5463731729730619\n",
      "1.5477332829730654\n",
      "1.5482769186647645\n",
      "1.5481072062932253\n",
      "1.5479374939216852\n",
      "1.5461348329335454\n",
      "1.545045520008644\n",
      "1.5432768825778158\n",
      "1.5430380675185271\n",
      "1.5427992524592418\n",
      "1.5440902597714934\n",
      "1.5469110894552895\n",
      "1.5497319191390795\n",
      "1.5503095783880918\n",
      "1.5516005857003459\n",
      "1.552178244949359\n",
      "1.5505127337635882\n",
      "1.5503770449493592\n",
      "1.550241356135132\n",
      "1.5501056673209068\n",
      "1.5485432823801972\n",
      "1.5476942455027225\n",
      "1.546006007044228\n",
      "1.543604420522488\n",
      "1.5420193083090472\n",
      "1.540571345897981\n",
      "1.5388490838821687\n",
      "1.537862897202328\n",
      "1.5368767105224896\n",
      "1.5381336942774309\n",
      "1.5377577294157727\n",
      "1.5366684164908717\n",
      "1.536395577874278\n",
      "1.5369392135659765\n",
      "1.5365632487043204\n",
      "1.5353708095343594\n",
      "1.535914445226059\n",
      "1.5364580809177624\n",
      "1.5370017166094654\n",
      "1.5367288779928645\n",
      "1.5364560393762643\n",
      "1.5347565046331813\n",
      "1.5354032665699444\n",
      "1.536050028506699\n",
      "1.536696790443464\n",
      "1.5365270780719205\n",
      "1.5348502706015656\n",
      "1.5331961904039388\n",
      "1.531542110206309\n",
      "1.52988803000868\n",
      "1.5298668984276516\n",
      "1.5282128182300212\n",
      "1.5305379833288402\n",
      "1.52888390313121\n",
      "1.5272298229335775\n",
      "1.5272086913525555\n",
      "1.5263710854632255\n",
      "1.5263499538822007\n",
      "1.5246958736845704\n",
      "1.5262045644750852\n",
      "1.5260803066489996\n",
      "1.5259560488229125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5265451390600697\n",
      "1.527134229297224\n",
      "1.526906845226079\n",
      "1.5273928092181754\n",
      "1.527878773210272\n",
      "1.526938041075888\n",
      "1.5259973089414998\n",
      "1.5250565768071112\n",
      "1.5257487932893299\n",
      "1.5256245354632432\n",
      "1.525500277637153\n",
      "1.5246626717478289\n",
      "1.5260682362932851\n",
      "1.5266573265304406\n",
      "1.5272464167675994\n",
      "1.5278355070047491\n",
      "1.5284245972419108\n",
      "1.5291168137241211\n",
      "1.5306255045146326\n",
      "1.5306271002063354\n",
      "1.5314451702063387\n",
      "1.5314467658980337\n",
      "1.5306318872814373\n",
      "1.5321633053446702\n",
      "1.5327751228545567\n",
      "1.5341343119849928\n",
      "1.5370233234869708\n",
      "1.539198986925702\n",
      "1.5405581760561322\n",
      "1.5417802153841946\n",
      "1.5430022547122535\n",
      "1.54422429404032\n",
      "1.5447329853051412\n",
      "1.5474848470047438\n",
      "1.5487068863328057\n",
      "1.549112451352565\n",
      "1.5495180163723263\n",
      "1.5499235813920889\n",
      "1.5496157983486116\n",
      "1.5478813191786542\n",
      "1.546860188071934\n",
      "1.547368879336759\n",
      "1.5472673487834012\n",
      "1.5464524701668019\n",
      "1.5478807619849813\n",
      "1.5470658833683808\n",
      "1.5470674790600834\n",
      "1.5477824228150225\n",
      "1.5470706704434833\n",
      "1.5470722661351812\n",
      "1.5470738618268791\n",
      "1.5463621094553426\n",
      "1.5457534833288569\n",
      "1.5459613315106757\n",
      "1.5467453779533626\n",
      "1.5468388036055358\n",
      "1.5469322292577043\n",
      "1.5470256549098749\n",
      "1.5476952788229201\n",
      "1.5483649027359616\n",
      "1.5475047042774623\n",
      "1.5473578538822044\n",
      "1.5472337307596744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "data=load_boston()\n",
    "\n",
    "\n",
    "def step_gradient(X, Y, learning_rate, m):\n",
    "    m_slope=np.array([0 for i in range(len(X[0]))])\n",
    "    M=len(X)\n",
    "    for i in range(M):\n",
    "        x=X[i]\n",
    "        y=Y[i]\n",
    "        for j in range(len(m_slope)):\n",
    "            m_slope[j]+=(-2/M)*(y-((m*x).sum()))*x[j]\n",
    "    new_m=m-learning_rate*m_slope\n",
    "    cost(new_m, X, Y)\n",
    "    return new_m\n",
    "    \n",
    "def cost(m, X, Y):\n",
    "    cst=0\n",
    "    for i in range(len(X)):\n",
    "        cst+=(2/len(X))*(Y[i]-sum(m*X[i]))\n",
    "    print(cst)\n",
    "    \n",
    "    \n",
    "def gd(X, Y, iterations, learning_rate):\n",
    "    m=np.array([0 for i in range(len(X[0]))])\n",
    "    for i in range(iterations):\n",
    "        m=step_gradient(X, Y, learning_rate, m)\n",
    "    return m\n",
    "\n",
    "\n",
    "\n",
    "def run():\n",
    "    X=data.data\n",
    "    Y=data.target\n",
    "    X=np.append(X, np.ones(len(X), dtype='int').reshape(-1, 1), axis=1)\n",
    "    iterations=500\n",
    "    learning_rate=0.000001\n",
    "    m=gd(X, Y, iterations, learning_rate)\n",
    "\n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
